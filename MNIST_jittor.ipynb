{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cfd990d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T14:59:31.081369Z",
     "start_time": "2022-04-04T14:59:29.764156Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0404 22:59:29.797014 04 log.cc:351] Load log_sync: 1\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:29.827454 04 compiler.py:951] Jittor(1.3.1.56) src: /home/hx-gpu3/anaconda3/envs/mmlab/lib/python3.9/site-packages/jittor\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:29.829971 04 compiler.py:952] g++ at /usr/bin/g++(7.5.0)\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:29.830405 04 compiler.py:953] cache_path: /home/hx-gpu3/.cache/jittor/jt1.3.1/g++7.5.0/py3.9.10/Linux-5.4.0-99x95/IntelRCoreTMi9x92/default\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:29.832758 04 compiler.py:896] Found nvcc(11.0.194) at /usr/local/cuda-11.0/bin/nvcc\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:29.868012 04 __init__.py:411] Found gdb(8.1.0) at /usr/bin/gdb.\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:29.871191 04 __init__.py:411] Found addr2line(2.30) at /usr/bin/addr2line.\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:29.929899 04 compiler.py:1006] cuda key:cu11.0.194_sm_86\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.026783 04 __init__.py:227] Total mem: 62.74GB, using 16 procs for compiling.\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.096048 04 jit_compiler.cc:28] Load cc_path: /usr/bin/g++\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.096599 04 jit_compiler.cc:31] Load nvcc_path: /usr/local/cuda-11.0/bin/nvcc\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.144345 04 init.cc:62] Found cuda archs: [86,]\u001b[m\n",
      "\u001b[38;5;3m[w 0404 22:59:30.191663 04 compiler.py:1351] CUDA arch(86)>80 will be backward-compatible\u001b[m\n",
      "gcc: error: unrecognized command line option ‘--showme:version’; did you mean ‘--no-version’?\n",
      "\u001b[38;5;2m[i 0404 22:59:30.205960 04 compile_extern.py:516] mpicc not found, distribution disabled.\u001b[m\n",
      "\u001b[38;5;3m[w 0404 22:59:30.220610 04 compile_extern.py:200] CUDA related path found in LD_LIBRARY_PATH or PATH(['', '/usr/local/cuda-11.1/lib64', '/home/hx-gpu3/anaconda3/envs/mmlab/bin', '/home/hx-gpu3/anaconda3/condabin', '/usr/local/sbin', '/usr/local/bin', '/usr/sbin', '/usr/bin', '/sbin', '/bin', '/usr/games', '/usr/local/games', '/snap/bin', '/usr/local/cuda-11.1/bin', '/home/hx-gpu3/.myscripts']), This path may cause jittor found the wrong libs, please unset LD_LIBRARY_PATH and remove cuda lib path in Path. \u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.234375 04 compile_extern.py:30] found /usr/local/cuda-11.0/include/cublas.h\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.239076 04 compile_extern.py:30] found /usr/local/cuda-11.0/lib64/libcublas.so\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.239667 04 compile_extern.py:30] found /usr/local/cuda-11.0/lib64/libcublasLt.so.11\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.589495 04 compile_extern.py:30] found /usr/local/cuda-11.0/include/cudnn.h\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.608380 04 compile_extern.py:30] found /usr/local/cuda-11.0/lib64/libcudnn.so.8\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.608918 04 compile_extern.py:30] found /usr/local/cuda-11.0/lib64/libcudnn_ops_infer.so.8\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.610536 04 compile_extern.py:30] found /usr/local/cuda-11.0/lib64/libcudnn_ops_train.so.8\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.611173 04 compile_extern.py:30] found /usr/local/cuda-11.0/lib64/libcudnn_cnn_infer.so.8\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:30.700855 04 compile_extern.py:30] found /usr/local/cuda-11.0/lib64/libcudnn_cnn_train.so.8\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:31.035095 04 compile_extern.py:30] found /usr/local/cuda-11.0/include/curand.h\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:31.058388 04 compile_extern.py:30] found /usr/local/cuda-11.0/lib64/libcurand.so\u001b[m\n",
      "\u001b[38;5;2m[i 0404 22:59:31.079294 04 cuda_flags.cc:32] CUDA enabled.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# classification mnist example \n",
    "import  os\n",
    "os.environ['nvcc_path']='/usr/local/cuda-11.0/bin/nvcc'\n",
    "import jittor as jt  # 将 jittor 引入\n",
    "from jittor import nn, Module  # 引入相关的模块\n",
    "import numpy as np\n",
    "import math \n",
    "from jittor import init\n",
    "if jt.has_cuda:\n",
    "    jt.flags.use_cuda = 1 # jt.flags.use_cuda 表示是否使用 gpu 训练。\n",
    "# 如果 jt.flags.use_cuda=1，表示使用GPU训练 如果 jt.flags.use_cuda = 0 表示使用 CPU\n",
    "from jittor.dataset.mnist import MNIST \n",
    "#由于 MNIST 是一个常见的数据集，其数据载入已经被封装进 jittor 所以可以直接调用。\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163be0a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T14:59:31.089066Z",
     "start_time": "2022-04-04T14:59:31.082914Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from PIL import Image\n",
    "from jittor.dataset import Dataset\n",
    "from jittor_utils.misc import download_url_to_local\n",
    "\n",
    "class MNIST(Dataset):\n",
    "    def __init__(self, data_root=\"./mnist_data/\", train=True ,download=True, batch_size=1, shuffle=False):\n",
    "        # if you want to test resnet etc you should set input_channel = 3, because the net set 3 as the input dimensions\n",
    "        super().__init__()\n",
    "        self.data_root = data_root\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.is_train = train\n",
    "        if download == True:\n",
    "            self.download_url()\n",
    "\n",
    "        filesname = [\n",
    "                \"train-images-idx3-ubyte.gz\",\n",
    "                \"t10k-images-idx3-ubyte.gz\",\n",
    "                \"train-labels-idx1-ubyte.gz\",\n",
    "                \"t10k-labels-idx1-ubyte.gz\"\n",
    "        ]\n",
    "        self.mnist = {}\n",
    "        if self.is_train:\n",
    "            with gzip.open(data_root + filesname[0], 'rb') as f:\n",
    "                self.mnist[\"images\"] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28, 28)\n",
    "            with gzip.open(data_root + filesname[2], 'rb') as f:\n",
    "                self.mnist[\"labels\"] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        else:\n",
    "            with gzip.open(data_root + filesname[1], 'rb') as f:\n",
    "                self.mnist[\"images\"] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28, 28)\n",
    "            with gzip.open(data_root + filesname[3], 'rb') as f:\n",
    "                self.mnist[\"labels\"] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        assert(self.mnist[\"images\"].shape[0] == self.mnist[\"labels\"].shape[0])\n",
    "        self.total_len = self.mnist[\"images\"].shape[0]\n",
    "        # this function must be called\n",
    "        self.set_attrs(batch_size = self.batch_size, total_len=self.total_len, shuffle= self.shuffle)\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.fromarray (self.mnist['images'][index]) \n",
    "        img = np.array (img)\n",
    "        img = img[np.newaxis, :]\n",
    "        return np.array((img / 255.0), dtype = np.float32), self.mnist['labels'][index]\n",
    "\n",
    "    def download_url(self):\n",
    "        resources = [\n",
    "            (\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", \"f68b3c2dcbeaaa9fbdd348bbdeb94873\"),\n",
    "            (\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\", \"d53e105ee54ea40749a09fcbcd1e9432\"),\n",
    "            (\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", \"9fb629c4189551a2d022fa330f9573f3\"),\n",
    "            (\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\", \"ec29112dd5afa0611ce80d1b7f02629c\")\n",
    "        ]\n",
    "\n",
    "        for url, md5 in resources:\n",
    "            filename = url.rpartition('/')[2]\n",
    "            download_url_to_local(url, filename, self.data_root, md5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8168975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T14:59:31.096639Z",
     "start_time": "2022-04-04T14:59:31.089740Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model (Module):\n",
    "    def __init__ (self):\n",
    "        super (Model, self).__init__()\n",
    "\n",
    "        self.relu = nn.Relu()\n",
    "        self.fc1 = nn.Linear (28*28, 512)\n",
    "        self.fc2 = nn.Linear (512, 10)\n",
    "    def execute (self, x) : \n",
    "        # it's simliar to forward function in Pytorch \n",
    "        x=jt.reshape(x,[x.shape[0],-1])\n",
    "        \n",
    "        x = self.fc1 (x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2 (x)\n",
    "#         x= nn.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99747bee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T15:00:38.650266Z",
     "start_time": "2022-04-04T14:59:31.097402Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1875 (0%)]\tLoss: 2.308344\n",
      "Train Epoch: 0 [500/1875 (27%)]\tLoss: 0.183193\n",
      "Train Epoch: 0 [1000/1875 (53%)]\tLoss: 0.183329\n",
      "Train Epoch: 0 [1500/1875 (80%)]\tLoss: 0.094363\n",
      "Train Epoch: 1 [0/1875 (0%)]\tLoss: 0.122191\n",
      "Train Epoch: 1 [500/1875 (27%)]\tLoss: 0.073456\n",
      "Train Epoch: 1 [1000/1875 (53%)]\tLoss: 0.051541\n",
      "Train Epoch: 1 [1500/1875 (80%)]\tLoss: 0.207473\n",
      "Train Epoch: 2 [0/1875 (0%)]\tLoss: 0.099142\n",
      "Train Epoch: 2 [500/1875 (27%)]\tLoss: 0.014521\n",
      "Train Epoch: 2 [1000/1875 (53%)]\tLoss: 0.017011\n",
      "Train Epoch: 2 [1500/1875 (80%)]\tLoss: 0.090822\n",
      "Train Epoch: 3 [0/1875 (0%)]\tLoss: 0.039820\n",
      "Train Epoch: 3 [500/1875 (27%)]\tLoss: 0.121215\n",
      "Train Epoch: 3 [1000/1875 (53%)]\tLoss: 0.016069\n",
      "Train Epoch: 3 [1500/1875 (80%)]\tLoss: 0.154921\n",
      "Train Epoch: 4 [0/1875 (0%)]\tLoss: 0.016104\n",
      "Train Epoch: 4 [500/1875 (27%)]\tLoss: 0.087170\n",
      "Train Epoch: 4 [1000/1875 (53%)]\tLoss: 0.002511\n",
      "Train Epoch: 4 [1500/1875 (80%)]\tLoss: 0.007997\n",
      "Train Epoch: 5 [0/1875 (0%)]\tLoss: 0.011221\n",
      "Train Epoch: 5 [500/1875 (27%)]\tLoss: 0.033907\n",
      "Train Epoch: 5 [1000/1875 (53%)]\tLoss: 0.025174\n",
      "Train Epoch: 5 [1500/1875 (80%)]\tLoss: 0.005739\n",
      "Train Epoch: 6 [0/1875 (0%)]\tLoss: 0.075746\n",
      "Train Epoch: 6 [500/1875 (27%)]\tLoss: 0.006817\n",
      "Train Epoch: 6 [1000/1875 (53%)]\tLoss: 0.005775\n",
      "Train Epoch: 6 [1500/1875 (80%)]\tLoss: 0.013450\n",
      "Train Epoch: 7 [0/1875 (0%)]\tLoss: 0.057265\n",
      "Train Epoch: 7 [500/1875 (27%)]\tLoss: 0.012524\n",
      "Train Epoch: 7 [1000/1875 (53%)]\tLoss: 0.000397\n",
      "Train Epoch: 7 [1500/1875 (80%)]\tLoss: 0.001480\n",
      "Train Epoch: 8 [0/1875 (0%)]\tLoss: 0.001511\n",
      "Train Epoch: 8 [500/1875 (27%)]\tLoss: 0.003453\n",
      "Train Epoch: 8 [1000/1875 (53%)]\tLoss: 0.000128\n",
      "Train Epoch: 8 [1500/1875 (80%)]\tLoss: 0.045478\n",
      "Train Epoch: 9 [0/1875 (0%)]\tLoss: 0.007995\n",
      "Train Epoch: 9 [500/1875 (27%)]\tLoss: 0.103311\n",
      "Train Epoch: 9 [1000/1875 (53%)]\tLoss: 0.000017\n",
      "Train Epoch: 9 [1500/1875 (80%)]\tLoss: 0.081951\n",
      "Train Epoch: 10 [0/1875 (0%)]\tLoss: 0.000341\n",
      "Train Epoch: 10 [500/1875 (27%)]\tLoss: 0.000832\n",
      "Train Epoch: 10 [1000/1875 (53%)]\tLoss: 0.000314\n",
      "Train Epoch: 10 [1500/1875 (80%)]\tLoss: 0.016303\n",
      "Train Epoch: 11 [0/1875 (0%)]\tLoss: 0.058477\n",
      "Train Epoch: 11 [500/1875 (27%)]\tLoss: 0.001477\n",
      "Train Epoch: 11 [1000/1875 (53%)]\tLoss: 0.000025\n",
      "Train Epoch: 11 [1500/1875 (80%)]\tLoss: 0.026331\n",
      "Train Epoch: 12 [0/1875 (0%)]\tLoss: 0.000160\n",
      "Train Epoch: 12 [500/1875 (27%)]\tLoss: 0.001673\n",
      "Train Epoch: 12 [1000/1875 (53%)]\tLoss: 0.000047\n",
      "Train Epoch: 12 [1500/1875 (80%)]\tLoss: 0.027241\n",
      "Train Epoch: 13 [0/1875 (0%)]\tLoss: 0.000529\n",
      "Train Epoch: 13 [500/1875 (27%)]\tLoss: 0.000013\n",
      "Train Epoch: 13 [1000/1875 (53%)]\tLoss: 0.000393\n",
      "Train Epoch: 13 [1500/1875 (80%)]\tLoss: 0.000038\n",
      "Train Epoch: 14 [0/1875 (0%)]\tLoss: 0.003282\n",
      "Train Epoch: 14 [500/1875 (27%)]\tLoss: 0.000005\n",
      "Train Epoch: 14 [1000/1875 (53%)]\tLoss: 0.000021\n",
      "Train Epoch: 14 [1500/1875 (80%)]\tLoss: 0.001543\n",
      "Train Epoch: 15 [0/1875 (0%)]\tLoss: 0.000233\n",
      "Train Epoch: 15 [500/1875 (27%)]\tLoss: 0.000036\n",
      "Train Epoch: 15 [1000/1875 (53%)]\tLoss: 0.002379\n",
      "Train Epoch: 15 [1500/1875 (80%)]\tLoss: 0.000003\n",
      "Train Epoch: 16 [0/1875 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 16 [500/1875 (27%)]\tLoss: 0.000034\n",
      "Train Epoch: 16 [1000/1875 (53%)]\tLoss: 0.017037\n",
      "Train Epoch: 16 [1500/1875 (80%)]\tLoss: 0.000179\n",
      "Train Epoch: 17 [0/1875 (0%)]\tLoss: 0.000006\n",
      "Train Epoch: 17 [500/1875 (27%)]\tLoss: 0.019927\n",
      "Train Epoch: 17 [1000/1875 (53%)]\tLoss: 0.002832\n",
      "Train Epoch: 17 [1500/1875 (80%)]\tLoss: 0.003627\n",
      "Train Epoch: 18 [0/1875 (0%)]\tLoss: 0.004243\n",
      "Train Epoch: 18 [500/1875 (27%)]\tLoss: 0.000052\n",
      "Train Epoch: 18 [1000/1875 (53%)]\tLoss: 0.000014\n",
      "Train Epoch: 18 [1500/1875 (80%)]\tLoss: 0.035261\n",
      "Train Epoch: 19 [0/1875 (0%)]\tLoss: 0.128716\n",
      "Train Epoch: 19 [500/1875 (27%)]\tLoss: 0.000088\n",
      "Train Epoch: 19 [1000/1875 (53%)]\tLoss: 0.000379\n",
      "Train Epoch: 19 [1500/1875 (80%)]\tLoss: 0.006748\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, optimizer, epoch, losses, losses_idx):\n",
    "    model.train()\n",
    "    lens = len(train_loader)\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        outputs = model(inputs)\n",
    "        loss = nn.cross_entropy_loss(outputs, targets)\n",
    "        optimizer.step (loss)\n",
    "        losses.append(loss.numpy()[0])\n",
    "#         losses_idx.append(epoch * lens + batch_idx)\n",
    "        \n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx, len(train_loader) ,\n",
    "                100. * batch_idx / len(train_loader), loss.numpy()[0]))\n",
    "\n",
    "def val(model, val_loader, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "        batch_size = inputs.shape[0]\n",
    "        outputs = model(inputs)\n",
    "        pred = np.argmax(outputs.numpy(), axis=1)\n",
    "        acc = np.sum(targets.numpy()==pred)\n",
    "        total_acc += acc\n",
    "        total_num += batch_size\n",
    "        acc = acc / batch_size\n",
    "        \n",
    "        if batch_idx % 1000 == 0:\n",
    "            print(f'Test Epoch: {epoch} [{batch_idx}/{len(val_loader)}]\\tAcc: {acc:.6f}')    \t\n",
    "            print('Test Acc =', total_acc / total_num)\n",
    "    \n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "epochs = 20\n",
    "losses = []\n",
    "losses_idx = []\n",
    "train_loader = MNIST(train=True, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_loader = MNIST(train=False, batch_size=1, shuffle=False)\n",
    "\n",
    "model = Model ()\n",
    "optimizer = nn.Adam(model.parameters(), learning_rate)\n",
    "for epoch in range(epochs):\n",
    "    train(model, train_loader, optimizer, epoch, losses, losses_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e0918d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T15:00:41.515345Z",
     "start_time": "2022-04-04T15:00:38.651096Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch: 19 [0/10000]\tAcc: 1.000000\n",
      "Test Acc = 1.0\n",
      "Test Epoch: 19 [1000/10000]\tAcc: 1.000000\n",
      "Test Acc = 0.978021978021978\n",
      "Test Epoch: 19 [2000/10000]\tAcc: 1.000000\n",
      "Test Acc = 0.9690154922538731\n",
      "Test Epoch: 19 [3000/10000]\tAcc: 1.000000\n",
      "Test Acc = 0.9700099966677774\n",
      "Test Epoch: 19 [4000/10000]\tAcc: 1.000000\n",
      "Test Acc = 0.971007248187953\n",
      "Test Epoch: 19 [5000/10000]\tAcc: 1.000000\n",
      "Test Acc = 0.9722055588882224\n",
      "Test Epoch: 19 [6000/10000]\tAcc: 1.000000\n",
      "Test Acc = 0.9741709715047492\n",
      "Test Epoch: 19 [7000/10000]\tAcc: 1.000000\n",
      "Test Acc = 0.9762891015569204\n",
      "Test Epoch: 19 [8000/10000]\tAcc: 1.000000\n",
      "Test Acc = 0.9785026871641045\n",
      "Test Epoch: 19 [9000/10000]\tAcc: 1.000000\n",
      "Test Acc = 0.9802244195089435\n"
     ]
    }
   ],
   "source": [
    "val(model, val_loader, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4fc44a",
   "metadata": {},
   "source": [
    "> B32 82s 0.77G  \n",
    "> B32 78s 0.77G  \n",
    "> B32 79s 0.77G  \n",
    "  \n",
    "> 69s  \n",
    "> 67s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mmlab]",
   "language": "python",
   "name": "conda-env-mmlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
